---
title: "Workshop Notes"
author: "Dan Tran"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: true
    toc_depth: 3
    df_print: kable
    highlight: zenburn
  html_document:
    toc: true
    toc_float: true
    theme: bootstrap
    df_print: paged
    highlight: zenburn
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(MXB107)
```

Workshop Recordings can be found on the Learning Resources Site:
<https://blackboard.qut.edu.au/bbcswebdav/pid-1481644-dt-announcement-rid-58665563_1/courses/MXB107_22se2/_site/videos.html>.

In this document, I'll only write things that are not included in the
official Workshop resources (above).

## Workshop 4 (23/8/22)

### Largest Dice Roll

Imagine everyone in this class is lost in a far-away desert. There is
not enough food, so we decide who get to eat by rolling two dices.

Team A would win if the largest face rolled between the two is 1,2,3 or
4.

Team B win otherwise (if the largest face is 5 or 6).

Let $A$ be the event that team A win, and $B$ the event that team B win.

|       | 1   | 2   | 3   | 4   | 5   | 6   |
|-------|-----|-----|-----|-----|-----|-----|
| **1** | A   | A   | A   | A   | B   | B   |
| **2** | A   | A   | A   | A   | B   | B   |
| **3** | A   | A   | A   | A   | B   | B   |
| **4** | A   | A   | A   | A   | B   | B   |
| **5** | B   | B   | B   | B   | B   | B   |
| **6** | B   | B   | B   | B   | B   | B   |

By counting, we observe that:

$$
\begin{aligned}
Pr(A) &= \dfrac{16}{36} \approx 44.4\% \\
Pr(B) &= \dfrac{20}{36} \approx 55.6\%
\end{aligned}
$$ 

We see that team B actually wins more often than team A.

### Bayesian: Rare Disease

There is a rare yet deadly disease that affects 0.1% of the population.
To diagnose the disease, scientists have made a test kit with 99%
accuracy. This is, if the patient indeed has the disease, it will test
positive 99% of the time (and if you are sick, there is a 1% chance that
it says negative). This also means that even if you are not sick, it can
give positive result 1% of the time.

#### Positive Once

What is the probability that you have the disease given that you tested
positive once?

**Answer**

Let $S$ be the event that you are sick, and $P$ be the event that you
test positive.

$$
\begin{aligned}
Pr(S) &= 0.001 \\
Pr(P | S) &= 0.99 \\
Pr(P | S^c) &= 0.01 \\
Pr(P^c |S) &= 0.01
\end{aligned}
$$ 

We need to find $Pr(S|P)$, Bayesian Theorem would state that:

$$
\begin{aligned}
Pr(S|P) &= \dfrac{Pr(P|S)Pr(S)}{Pr(P)} \\
Pr(P) &= Pr(P|S)Pr(S) + Pr(P|S^c)Pr(S^c) & (\text{Law of total probability}) \\
\\ \text{Substitution:} \\
\Rightarrow Pr(S|P) &= \dfrac{Pr(P|S)Pr(S)}{Pr(P|S)Pr(S) + Pr(P|S^c)Pr(S^c)} \\
&= \dfrac{0.99\times0.001}{0.99\times 0.001 + 0.01\times0.999} \\
&\approx 0.0901\approx9.01\%
\end{aligned}
$$ 

Hence, if you tested positive once, the probability that you actually
have the disease is 9.01% (which is not that bad!).

#### Positive Twice\*

\*This is a challenging question for extension.

Now, you took another test and got a positive result. What is the
probability that you have the disease now?

**Answer**

Renamed the above $P$ to $P_1$, we have:

$$
Pr(S|P_1) \approx 0.0901
$$ For two tests, we have:

$$
Pr(S|P_2 \cap P_1) = \dfrac{Pr(P_2 \cap P_1 | S)Pr(S)}{Pr(P2\cap P_1|S)Pr(S) + Pr(P_2 \cap P_1|S^c)Pr(S^c)}
$$ 

Realise that $P_1$ and $P_2$ are independent, we see that 

$$
Pr(P_2\cap P_1|S)=Pr(P_2|S)Pr(P_1|S)\\
Pr(P_2\cap P_2|S^c)=Pr(P_2|S^c)Pr(P_1|S^c)
$$

Hence,

$$
\begin{aligned}
Pr(S|P_2 \cap P_1) &= \dfrac{Pr(P_2 \cap P_1 | S)Pr(S)}{Pr(P2\cap P_1|S)Pr(S) + Pr(P_2 \cap P_1|S^c)Pr(S^c)}\\
&=\dfrac{Pr(P_2|S)Pr(P_1|S)Pr(S)}{Pr(P_2|S)Pr(P_1|S)Pr(S) + Pr(P_2|S^c)Pr(P_1|S^c)Pr(S^c)}\\
&=\dfrac{0.99\times0.99\times0.001}{0.99\times0.99\times0.001 + 0.01\times0.01\times0.99}\\
&\approx0.9082 \approx 90.82\%
\end{aligned}
$$ 

So the new probability is now 90.82%.

## Workshop 5 (30/8/22)

### Sum of Two Dices

Let X be the random variable generated by summing the results of two
dices.

**a. Find the probability mass function**

|       | 1   | 2   | 3   | 4   | 5   | 6   |
|-------|-----|-----|-----|-----|-----|-----|
| **1** | 2   | 3   | 4   | 5   | 6   | 7   |
| **2** | 3   | 4   | 5   | 6   | 7   | 8   |
| **3** | 4   | 5   | 6   | 7   | 8   | 9   |
| **4** | 5   | 6   | 7   | 8   | 9   | 10  |
| **5** | 6   | 7   | 8   | 9   | 10  | 11  |
| **6** | 7   | 8   | 9   | 10  | 11  | 12  |

: Remember, probability mass function is the probability of each event
X:

$$
p(x)=Pr(X=x), x\in \{2,3,4,5,6,7,8,9,10,11,12\}
$$

By counting, we find that

$$
p(x)=\begin{cases}
\dfrac{1}{36} & ,x=2,12 \\
\dfrac{2}{36} & ,x=3,11 \\
\dfrac{3}{36} & ,x=4,10 \\
\dfrac{4}{36} & ,x=5,9 \\
\dfrac{5}{36} & ,x=6,8 \\
\dfrac{6}{36} & ,x=7 \\
\end{cases}
$$

**b. Find the mean**

$$
\begin{aligned}
E[X] &= \sum_{S}xp(x)\\
&= \sum_{x=2}^{12}xp(x)\\
&= \dfrac{1}{36} \times 2 + \dfrac{2}{36} \times 3 + \dfrac{3}{36} \times 4 + \dfrac{4}{36} \times 5 + \dfrac{5}{36} \times 6 + \dfrac{6}{36} \times 7 \\ &+ \dfrac{5}{36} \times 8 + \dfrac{4}{36} \times 9 + \dfrac{3}{36} \times 10 + \dfrac{2}{36} \times 11 + \dfrac{1}{36} \times 12\\
&= 7
\end{aligned}
$$

Hence the mean is 7.

**c. Find the median**

$$
\text{median of X} = \left\{ x \in S | Pr(X\leq x) \geq \dfrac{1}{2}, Pr(X\geq x) \geq \dfrac{1}{2} \right\}
$$

Try $x = 8$:

$$
\begin{aligned}
Pr(X \leq 8) &= Pr(X=1)+Pr(X=2)+Pr(X=3)+\cdots+Pr(X=8)\\
&= \dfrac{1}{36} + \dfrac{2}{36} + \dfrac{3}{36} + \dfrac{4}{36} + \dfrac{5}{36} + \dfrac{6}{36} + \dfrac{5}{36}\\
\approx&0.72 \geq \dfrac{1}{2}\\
Pr(X \geq 8) &= Pr(X=8)+Pr(X=9)+Pr(X=10)+Pr(X=11)+Pr(X=12)\\
&= \dfrac{5}{36} + \dfrac{4}{36} + \dfrac{3}{36} + \dfrac{2}{36} + \dfrac{1}{36} \\
\approx&0.42 \leq \dfrac{1}{2}
\end{aligned}
$$

Hence $x = 8$ is not the median of X.

Try $x = 7$:

$$
\begin{aligned}
Pr(X \leq 7) &= Pr(X=1)+Pr(X=2)+Pr(X=3)+\cdots+Pr(X=8)\\
&= \dfrac{1}{36} + \dfrac{2}{36} + \dfrac{3}{36} + \dfrac{4}{36} + \dfrac{5}{36} + \dfrac{6}{36}\\
\approx&0.58 \geq \dfrac{1}{2}\\
Pr(X \geq 7) &= Pr(X=8)+Pr(X=9)+Pr(X=10)+Pr(X=11)+Pr(X=12)\\
&= \dfrac{6}{36} + \dfrac{5}{36} + \dfrac{4}{36} + \dfrac{3}{36} + \dfrac{2}{36} + \dfrac{1}{36} \\
\approx&0.58 \geq \dfrac{1}{2}
\end{aligned}
$$

Hence $x = 7$ is the median of X.

**d. Find the mode**

$$
\text{mode of X} = \max_{x \in S}p(x)
$$

In this case, we know

$$
S = \{2,3,4,5,6,7,8,9,10,11,12\}
$$

and based on the $p(x)$ defined above, the most common sum is 7, where
$p(7) = \dfrac{6}{36}$.

Hence the mode is 7.

Since mean = median = mode, we say $X$ is defined by a symmetric,
uni-modal distribution (i.e. no skew).

**e. Find the variance and standard deviation**

$$
\begin{aligned}
Var[X] &= E[(X-\mu]^2]\\
&= \sum_S(x-\mu)^2p(x)\\
&= \sum_{x=2}^{12}(x-7)^2p(x)\\
&= (2-7)^2 \times \dfrac{1}{36} + (3-7)^2 \times \dfrac{2}{36} + (4-7)^2 \times \dfrac{3}{36} + \cdots + (11-7)^2 \times \dfrac{2}{36} + (12-7)^2 \times \dfrac{1}{36}\\
\approx& 5.83\\
\sigma\approx& \sqrt{5.83} \approx2.41
\end{aligned}
$$

Hence the variance of X is 5.83 and the standard deviation is 2.41.

## Workshop 6 (6/9/22)

### Butter weight

Example: A dairy produces packages of butter using a machine that is set
to produce 250 g block of butter with a standard deviation of 10 g. A
sample of size n=13 blocks of butter produce an average weight of
$\bar{x}$=253 g. What is the probability of observing a sample average
weight of 253 g or more?

Set up the solution by hand and use R to compute the probability.

**Answer**

What we have known:

$$
\mu = 250g\\
\sigma = 10g\\
n=13 \text{ blocks}
$$ Apply the central limit theorem:

$$
\bar{x} \sim N\left(\mu, \dfrac{\sigma^2}{n}\right)\\
\bar{x} \sim N\left(250, \dfrac{10^2}{13}\right)\\
$$ In a normal distribution, the first parameter is the mean, and second
is the variance.

And the standard deviation of the distribution of means is $$
\begin{aligned}
s &= \sqrt{\dfrac{\sigma^2}{n}} \\
&= \dfrac{\sigma}{\sqrt{n}} \\
&= \dfrac{10}{\sqrt{13}}
\end{aligned}
$$

To convert from any random variable to Z score:

$$
Z = \dfrac{X - \mu}{s}
$$

Hence:

$$
\begin{aligned}
Pr(\bar{x} \geq 253) &= Pr\left(\dfrac{\bar{x} - \mu}{s} \geq \dfrac{253 - \mu}{s}\right)\\
&= Pr\left(Z \geq \dfrac{253 - \mu}{s}\right)\\
&= Pr\left(Z \geq \dfrac{253 - \mu}{\sigma / \sqrt{n}}\right)\\
&= Pr\left(Z \geq \dfrac{253-250}{10/\sqrt{13}}\right)\\
&= Pr\left(Z \geq 1.08167\right)
\end{aligned}
$$

For a number $t$ up table shows $Pr(Z < t)$. We want
$Pr(Z \geq t) = 1 - Pr(Z < t)$

From lookup table:

$$
Pr(Z < 1.08) \approx 0.85993\\
Pr(Z > 1.08) \approx 1 - 0.85993\approx0.14007
$$

```{r}
pnorm(253, mean = 250, sd = 10/sqrt(13), lower.tail = FALSE)
pnorm(1.08167, mean = 0, sd = 1, lower.tail = FALSE)
```

Therefore, the probability of observing a sample average weight of 253g
or more is approximately 0.14.

### Online Workshop Preference

**Example**

Assume that in Semester 2 of a sample of 100 QUT students living in the
Greater Brisbane Area, 47 replied that they preferred on-line workshops.
Results of previous surveys from Semester 1 indicated that 35% of
students preferred on-line workshops. What is the probability of
observing the proportion from Semester 2, or more given the Semester 1
results are accurate?

The central limit theorem for a sample proportion has that: $$
\hat{p} \sim N\left(p,\dfrac{p(1-p)}{n}\right)
$$

Given:

$$
n = 100\\
p = \dfrac{x}{n} = \dfrac{47}{100}= 0.47\\
$$

Let $\hat{p}$ be the proportion of students who prefer online workshops
in semester 2

Variance of
$\hat{p} = \dfrac{p(1-p)}{n}=\dfrac{0.35\times(1-0.35)}{100}=0.002275$.
And the standard deviation of $\hat{p}$ is $s = \sqrt{0.002275}$

$$
\begin{aligned}
Pr(\hat{p} > 47) &= Pr(\dfrac{\hat{p} - 0.35}{\sqrt{0.002275}} > \dfrac{0.47 - 0.35}{\sqrt{0.002275}})\\
&= Pr(Z > 2.515)\\
&\approx 0.0062 
\end{aligned}
$$

```{r}
pnorm(2.5, lower.tail = FALSE)
```

Therefore, the probability of observing the proportion from semester 2
(0.47) or more, givne the results from semester 1 is accurate is
approximately 0.0062 or 0.62%.

## Workshop 7 (13/9/22)

### Method of Moments

Find the method of moments estimator for the exponential distribution
where

$$
f(x) = \lambda e^{-\lambda x}
$$

First moment is the mean of the sample:

$$
m_1 = \tilde{E[X]}
$$

Where X follows an exponential distribution. We can find E\[X\] in terms
of $\lambda$, then solve for $\lambda$.

$$
E[X] = \int_{_x}{\lambda e^{-\lambda x} dx}\\
= \dfrac{1}{\lambda}
$$

$$
m_1 = \dfrac{1}{\lambda} \\
\lambda = \dfrac{1}{m_1}
$$ Because we need to find an estimation from the sample mean, not an
exact population mean, change the notation accordingly:

$$
\lambda \rightarrow \tilde{\lambda}\\
m_1 \rightarrow \bar{x}
$$

Therefore, the method of moments estimator for the exponential
distribution is:

$$
\tilde{\lambda} = \dfrac{1}{\bar{x}}
$$

### Method of Maximum Likelihood Estimation

$$
f(x) = \lambda e^{-\lambda x}
$$

This gives the maximum likelihood function:

$$
\begin{aligned}
L(\lambda|\mathbf{x}) &= \prod_{i=1}^{n}f(x_i) \\
&=e^{-\lambda x_1}e^{-\lambda x_2}\cdots e^{-\lambda x_n}
\end{aligned}
$$

The log likelihood function:

$$
\begin{aligned}
l(\lambda|\mathbf{x}) &= log(L(\lambda|\mathbf{x})) \\
&= log(\lambda e^{-\lambda x_1}\lambda e^{-\lambda x_2}\cdots \lambda e^{-\lambda x_n})\\
&= log(\lambda e^{-\lambda x_1}) + log(\lambda e^{-\lambda x_2}) + \cdots + log(\lambda e^{-\lambda x_n})\\
&= \sum_{i=1}^{n}log(\lambda e^{-\lambda x_i})\\
&= \sum_{i=1}^{n}(log(\lambda) + log(e^{-\lambda x_i}))\\
&= \sum_{i=1}^{n}(log(\lambda) -\lambda x_i)\\
&= n\log(\lambda) - \lambda \sum_{i=1}^{n}x_i
\end{aligned}
$$

Find the derivative of the log likelihood function:

$$
\begin{aligned}
\dfrac{d}{d\lambda}l(\lambda|\mathbf{x}) &= \dfrac{d}{d\lambda}nlog(\lambda) - \dfrac{d}{d\lambda}(\lambda\sum_{i=1}^{n}x_i) \\
&= n \dfrac{1}{\lambda} - \sum_{i=1}^{n}x_i
\end{aligned}
$$

Set the derivative to 0 and find $\lambda$.

\$\$

```{=tex}
\begin{aligned}

n \dfrac{1}{\lambda} - \sum_{i=1}^{n}x_i &= 0\\
\dfrac{n}{\lambda} &= \sum_{i=1}^{n}x_i\\
\lambda &= \dfrac{n}{\sum_{i=1}^{n}}\\
\lambda &= \dfrac{1}{\dfrac{\sum_{i=1}^{n}x_i}{n}}\\
\lambda &= \dfrac{1}{\bar{x}}
\end{aligned}
```
\$\$

Because we are finding and estimation,
$\lambda \rightarrow \hat{\lambda}$

$$
\hat{\lambda} = \dfrac{1}{\bar{x}}
$$

### Bonus: Finding log likelihood of Poisson

```{=tex}
\begin{aligned}

L(x|\mathbf{x}) &= \prod_{i=1}^{n}\dfrac{\lambda^{x_i}}{x_i!}e^{-\lambda} \\

l(x|\mathbf{x}) &= \sum_{i=1}^{n}log(\dfrac{\lambda^{x_i}}{x_i!}e^{-\lambda})\\
&= \sum_{i=1}^{n}(log(\lambda ^{x_i}) + log(\dfrac{1}{x_i!}) + log(e^{-\lambda}))\\
&= \sum_{i=1}^{n}(x_ilog(\lambda) - log(x_i!) - \lambda)\\
&= log(\lambda)\sum_{i=1}^{n}x_i- \sum_{i=1}^{n}log(x_i!)- n\lambda
\end{aligned}
```

Z-score transformation

$$
Z = \dfrac{X-\mu}{\sigma} \\
Z\sigma=X - \mu
$$

Normal distribution of means from central limit theorem:

$$
\bar{x} \sim N\left(\mu, \dfrac{\sigma^2}{n}\right)\\
Z\dfrac{\sigma}{\sqrt{n}} = \bar{x} - \mu\\
\bar{x} = Z\dfrac{\sigma}{\sqrt n} + \mu
$$

For a type I error rate of $\alpha$, denoted $Z_\alpha$:

$$
Pr(Z > Z_\alpha) = 1 - \alpha
$$

A sample of n=50 adult men reveals that their average daily intake of
protein is xÂ¯=75.6 grams per day with a standard deviation of s=3.5
grams. Construct a 95% confidence interval for the average daily intake
of protein for men.

The confidence interval is

$$
n = 50 \\ \bar{x} = 75.6 \\ s = 3.5\\ \alpha = 0.05 \\

\bar{x} \pm Z\_{\alpha/2}SE\_{\bar{x}} \\

SE\_{\bar{x}} = \dfrac{s}{\sqrt{n}} = \dfrac{3.5}{\sqrt{50}} \\
Z\_{\alpha/2} = Z\_{0.05/2} = 1.96\\

\bar{x} \pm 1.96\\dfrac{3.5}{\\sqrt{50}} \\ \bar{x} \pm 0.970 \\ 75.6
\pm 0.97 \\ (74.63, 76.57)

$$

The 95% confidence interval is (74.63, 76.57).

A random sample of n=985 Queensland residents seeking their opinions on
how the Queensland State Government was handling the COVID-19 crisis. Of
those surveyed, x=592 indicated that they approved of the current
government's handling of the COVID-19 crisis. Construct a 90% confidence
interval for the proportion of the population that approves of the
current government's handling of the COVID-19 crisis.

$$ 
\begin{aligned}
n &= 985\\ 
x &= 592\\ 
\Rightarrow \hat{p} &= \dfrac{x}{n} =
\dfrac{592}{985} \approx 0.60 \\

\alpha &= (1 - 0.9) = 0.1, \text{90% confidence interval} \\

SE\_{\hat{p}} &= \sqrt{\dfrac{\hat{p}(1-\hat{p})}{n}} \\ 
&=\sqrt{\dfrac{0.60(1 - 0.60)}{985}} \\ &\approx 0.0156\\ Z\_{\alpha/2} 
&=Z\_{0.1/2} 
\approx 1.645\\

\hat{p} &\pm Z\_{\alpha/2}SE\_{\hat{p}} \\ 0.60 &\pm 1.645 \times 0.0156
\\ 0.60 &\pm 0.0256\\

&(0.574, 0.625)
\end{aligned}
$$

```{r}
0.6 + 1.645 * 0.0156
```

### Practical Question 2

Find the confidence interval for the mean of the IMDB.Ranking for Star
Trek (The Original Series).

```{r}
library(MXB107)
data(episodes)

original_episodes <- episodes %>% filter(Series.Name == "The Original Series")

# Stating your variables
x_bar <- original_episodes$IMDB.Ranking %>% mean()
n <- nrow(original_episodes)
s <- original_episodes$IMDB.Ranking %>% sd()

# Find Standard Error
se <- s / sqrt(n)
print(se)

# Find critical Z score
alpha <- 0.05
Z_alpha_half <- qnorm(1 - alpha/2)

# Apply confidence interval formula
upper_limit <- x_bar + Z_alpha_half * se
lower_limit <- x_bar - Z_alpha_half * se

# Display results
lower_limit
upper_limit
```

```{r}
params<-episodes%>%
  filter(Series == "TOS")%>%
  summarise(xbar = mean(IMDB.Ranking),std_dev = sd(IMDB.Ranking), N = n())

xbar <- pull(params,xbar)
s <- pull(params,std_dev)
n <- pull(params,N)

SE<-s/sqrt(n)

UCL<-xbar+1.96*SE

LCL<-xbar-1.96*SE

LCL
UCL
```

## Workshop 8 (20/9/22)

### Online Shopping Example

The quality of a product can be reflected by their star ratings.

When browsing for a new pair of Airbuds on JB Hifi, I found two choices
with the following rating distributions.

Sources:
<https://www.jbhifi.com.au/products/lg-tone-free-fp9a-wireless-anc-in-ear-headphones-with-plug-play#reviews>
<https://www.jbhifi.com.au/products/sony-wf-1000xm4-truly-wireless-noise-cancelling-in-ear-headphones-black#reviews>

```{r}
earphones <- data.frame(
  "Ratings" = 1:5,
  "Sony" = c(67, 48, 94, 273, 759),
  "LG" = c(4,5,3,25,109)
)

earphones %>%
  pivot_longer(c("Sony","LG")) %>%
  ggplot(aes(x = Ratings, y=value)) +
  geom_histogram(stat="identity") +
  geom_text(aes(label=value), vjust=-0.25)+
  facet_wrap(~name)+
  xlab("Rating")+
  ylab("Number of customers")+
  ggtitle("Customer Ratings on JB Hifi for LG and Sony Airbuds")
```

Some of their important statistics can also be calculated:

```{r}
alpha <- 0.05
n_lg <- sum(earphones$LG)
n_sony <- sum(earphones$Sony)

averages <- earphones %>% summarise_at(c("Sony","LG"), funs(average = sum(Ratings*.)/sum(.)))
lg_bar <- averages$LG_average
lg_s <- sum((earphones$Ratings - lg_bar)^2 * earphones$LG) / (sum(earphones$LG) - 1)

sony_bar <-averages$Sony_average
sony_s <- sum((earphones$Ratings - sony_bar)^2 * earphones$Sony) / (sum(earphones$Sony) - 1)

Z_critical <- qnorm(1 - alpha)
cat("LG Size:\t", n_lg, "\n")
cat("LG Average:\t", lg_bar, "\n")
cat("LG sd:\t\t", lg_s, "\n")
cat("Sony Size:\t", n_sony, "\n")
cat("Sony Average:\t", sony_bar, "\n")
cat("Sony sd:\t", sony_s, "\n")
```

Which one would you pick?

We all lean towards the Sony one with more ratings, but lower average.

**Go to www.menti.com and use the code 2380 3183**

#### Are they both good?

It is generally believed that a good product should have an average
rating of at least 4.25 (or 85%). Given the reviews above, is there
enough evidence to conclude that both Airbuds are good products, given a
Type I error rate of 0.05?

Since we want to find if a product has greater than or at least 4.25
stars on average. This should be our alternate hypothesis.

$$
H_A = \mu \geq 4.25
$$

That means our null hypothesis is:

$$
H_0 = \mu < 4.25
$$

For a type I error rate of $\alpha = 0.05$, the critical value is:

```{r}
alpha <- 0.05
Z_critical <- qnorm(1 - alpha) # Since this is a one sided test
Z_critical
```

$$
Z_{\alpha} = Z_{0.05} \approx 1.645
$$

Find the test statistics:

a)  For the Sony earbuds:

Sony Size: 1241 Sony Average: 4.296535 Sony sd: 1.241028

$$
\begin{aligned}
n &= 1241\\
\bar{x} &= 4.297\\
s &= 1.241\\
\mu_0 &= 4.25 \\
Z &= \dfrac{\bar{x} - \mu_0}{s/\sqrt{n}}\\
&= \dfrac{4.297 - 4.25}{1.241/\sqrt{1241}}\\
&= 1.334
\end{aligned}
$$

Check if test statistics is greater than critical statistics (because
the null hypothesis has the form $H_0: \mu \leq \mu_0$.

$$
Z > Z_{\alpha}?\\
Z = 1.334 < 1.645
$$

This means our test statistics does not pass the test. We fail to reject
the null hypothesis.

Alternately, we say that the Sony earbuds may not be a good product.

```{r}
(4.297 - 4.25)/(1.241/sqrt(1241))
```

b)  For the LG earbuds:

LG Size: 146 LG Average: 4.575342 LG sd: 0.8253188

$$
\begin{aligned}
n &= 146\\
\bar{x} &= 4.575\\
s&= 0.825\\
\mu_0 &= 4.25\\
Z_\alpha &= 1.645\\
Z &= \dfrac{\bar{x} - \mu_0}{s/\sqrt{n}}\\
&= \dfrac{4.575 - 4.25}{0.825/\sqrt{146}}\\
&\approx 4.760 > Z_{\alpha}
\end{aligned}
$$

We reject the null hypothesis and accept that the LG earbuds is a good
product.

```{r}
(4.575 - 4.25) / (0.825/sqrt(146))
```

#### Which pair is better, statistically?

Perform a test to check if the LG buds are statistically better than the
Sony buds.

Define our alternate hypothesis as:

$$
H_A: \mu_{LG} > \mu_{Sony}\\
H_A: \mu_{LG} - \mu_{Sony} > 0
$$

That means our null hypothesis is:

$$
H_0: \mu_{LG} - \mu_{Sony} \leq 0
$$

This is a one sided test.

LG Size: 146 LG Average: 4.575342 LG sd: 0.8253188 Sony Size: 1241 Sony
Average: 4.296535 Sony sd: 1.241028

$$
\begin{aligned}
\Delta_0 &= 0 \\
\bar{x_{lg}} &=  4.575\\
s_{lg} &= 0.825\\
n_{lg} &= 146\\
\bar{x_{sony}} &= 4.297\\
s_{sony} &= 1.241\\
n_{sony} &= 1241\\
\end{aligned}
$$

Since $\alpha = 0.05$, the critical Z score is the same as above:

$$
Z_\alpha = 1.645
$$

$$
\begin{aligned}
Z &= \dfrac{(\bar{x_{lg}} - \bar{x_{sony}})-\Delta_0}{\sqrt{\dfrac{s_{lg}^2}{n_{lg}}+\dfrac{s_{sony}^2}{n_{sony}}}}\\
&= \dfrac{(4.575 - 4.297) - 0}{\sqrt{\dfrac{0.825^2}{146}+\dfrac{1.241^2}{1241}}}\\
&\approx 3.618
\end{aligned}
$$

```{r}
num <- 4.575 - 4.297
den <- sqrt(0.825^2/146 + 1.241^2/1241)
num/den
```

Test if the test statistics is greater than the critical statistic
($Z_{\alpha} = 1.645$).

$$
Z > Z_\alpha\\
\text{since}\\
3.618 > 1.645
$$

Hence, we reject the null hypothesis and conclude that the LG buds are
better than the Sony buds in terms of ratings.

## Workshop 9 (4/10/22)

## Workshop 10 (11/10/22)

## Workshop 11 (18/10/22)

## Workshop 12 (23/10/22)
